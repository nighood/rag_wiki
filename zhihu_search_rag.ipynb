{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ[\"LLAMA_INDEX_CACHE_DIR\"] = '/mnt/nfs/renjiyuan/HF_cache'\n",
    "os.environ['HF_HOME'] = '/mnt/nfs/renjiyuan/HF_cache'\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/mnt/nfs/renjiyuan/HF_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renjiyuan/miniconda3/envs/rag_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Setup AzureOpenAI Agent\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    engine=\"gpt-4\",\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test api:\n",
      " beyond! \n",
      "\n",
      "This phrase is the famous catchphrase of the character Buzz Lightyear from the \"Toy Story\" franchise, which is produced by Pixar Animation Studios and released by Walt Disney Pictures. The character, who is a space ranger action figure, uses this line to express his adventurous spirit and his belief that there are no limits to what he can achieve. It has become an iconic line associated with the character and the movies.\n"
     ]
    }
   ],
   "source": [
    "# test llm api\n",
    "completion_response = llm.complete(\"To infinity, and\")\n",
    "print('Test api:\\n', completion_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhihu_search_tool import ZhihuSearchToolSpec\n",
    "from llama_index.core.tools.tool_spec.load_and_search.base import LoadAndSearchToolSpec\n",
    "\n",
    "# setup GoogleSearchToolSpec\n",
    "# key and engine could be found in https://developers.google.com/custom-search/v1/introduction?hl=zh-cn\n",
    "engine = '4690d06089adf4627'\n",
    "key = 'AIzaSyBSu-P_vk0i3Be7E5TMB_q6L-i5vR61u_s'\n",
    "zhihu_spec = ZhihuSearchToolSpec(key=key, engine=engine)\n",
    "\n",
    "# prepare tools\n",
    "tools = LoadAndSearchToolSpec.from_defaults(\n",
    "    zhihu_spec.to_tool_list()[0],\n",
    ").to_tool_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# setting the embed model, for default embed model is openai.\n",
    "# If you have the key of openai, you can set it in the env and skip this step.\n",
    "Settings.embed_model = resolve_embed_model(\"local:BAAI/bge-small-en-v1.5\")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.agent import AgentRunner\n",
    "# this method will automatically pick the best agent depending on the LLM\n",
    "# agent = AgentRunner.from_llm(tools, llm=llm, verbose=True)\n",
    "\n",
    "# or\n",
    "from llama_index.core.agent import ReActAgent\n",
    "agent = ReActAgent.from_tools(tools, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is Chinese. I need to use a tool to help me answer the question.\n",
      "Action: zhihu_search\n",
      "Action Input: {'query': 'DILab 是谁'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Content loaded! You can now search the information using read_zhihu_search\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: Now that the content is loaded, I need to use the read_zhihu_search tool to find out who or what DILab is.\n",
      "Action: read_zhihu_search\n",
      "Action Input: {'query': 'DILab 是什么'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: DILab是一个决策实验室，它在知乎上有一个账户，并且在该平台上分享有关人工智能和机器学习的内容。\n",
      "\u001b[0m\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer.\n",
      "Answer: DILab 是一个专注于人工智能和机器学习的决策实验室，它在知乎上拥有一个账户，并在该平台上分享相关领域的内容。\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='DILab 是一个专注于人工智能和机器学习的决策实验室，它在知乎上拥有一个账户，并在该平台上分享相关领域的内容。', sources=[ToolOutput(content='Content loaded! You can now search the information using read_zhihu_search', tool_name='zhihu_search', raw_input={'args': (), 'kwargs': {'query': 'DILab 是谁'}}, raw_output='Content loaded! You can now search the information using read_zhihu_search', is_error=False), ToolOutput(content='DILab是一个决策实验室，它在知乎上有一个账户，并且在该平台上分享有关人工智能和机器学习的内容。', tool_name='read_zhihu_search', raw_input={'args': (), 'kwargs': {'query': 'DILab 是什么'}}, raw_output='DILab是一个决策实验室，它在知乎上有一个账户，并且在该平台上分享有关人工智能和机器学习的内容。', is_error=False)], source_nodes=[], is_dummy_stream=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test \n",
    "agent.chat(\"DILab 是谁?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
